<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:mysql://BDS-TEST-003:3306/hive_metastore?createDatabasIfNotExist=true&amp;characterEncoding=UTF-8&amp;useUnicode=true</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>com.mysql.jdbc.Driver</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>hive</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>hive</value>
    </property>
    <property>
        <name>datanucleus.fixedDatastore</name>
        <value>false</value>
    </property>
    <property>
        <name>datanucleus.autoCreateSchema</name>
        <value>true</value>
    </property>
    <property>
        <name>datanucleus.autoCreateTables</name>
        <value>true</value>
    </property>
    <property>
        <name>datanucleus.autoCreateColumns</name>
        <value>true</value>
    </property>
    <property>
        <name>hive.exec.dynamic.partition.mode</name>
        <value>nonstrict</value>
    </property>
    <property>
        <name>hive.exec.max.dynamic.partitions</name>
        <value>100000</value>
    </property>
    <property>
        <name>hive.exec.max.dynamic.partitions.pernode</name>
        <value>10000</value>
    </property>
    <property>
        <name>hive.metastore.uris</name>
        <value>thrift://bds-test-001:9083</value>
    </property>
    <!--<property>
        <name>io.compression.codecs</name>
        <value>org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec,com.hadoop.compression.lzo.LzopCodec,org.apache.hadoop.io.compress.SnappyCodec</value>
    </property>
    <property>
        <name>io.compression.codec.lzo.class</name>
        <value>com.hadoop.compression.lzo.LzoCodec</value>
    </property>-->
    <!-- rename bug workaround https://issues.apache.org/jira/browse/HIVE-3815 -->
    <property>
        <name>fs.hdfs.impl.disable.cache</name>
        <value>false</value>
    </property>
    <property>
        <name>fs.file.impl.disable.cache</name>
        <value>false</value>
    </property>
    <!-- memory leak workaround https://issues.apache.org/jira/browse/HIVE-4501-->
    <!--
    <property>
      <name>hive.server2.thrift.http.max.worker.threads</name>
      <value>5000</value>
    </property>
    -->
    <!--<property>
        <name>hive.metastore.warehouse.dir</name>
        <value>hdfs://ns1/user/hadoop</value>
    </property>-->
    <property>
        <name>hive.exec.max.dynamic.partitions.pernode</name>
        <value>10000</value>
    </property>
</configuration>